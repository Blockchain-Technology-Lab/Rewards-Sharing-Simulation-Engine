{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Rewards Sharing Simulation Engine - Documentation This is the documentation for the Rewards Sharing Simulation Engine built by the University of Edinburgh's Blockchain Technology Lab. The source code is available on Github . Overview The simulation models the behaviour of stakeholders in a Proof-of-Stake system, i.e. the way they use their stake to engage with the protocol depending on the rewards they expect to receive. It focuses particularly on the way different stakeholders combine their resources and create stake pools (it assumes an on-chain pooling mechanism like the one in Cardano) and follows the dynamics of the system until it (potentially) reaches an equilibrium. The implementation is based on the Cardano blockchain, but can be generalized to systems that use similar reward sharing schemes (e.g. Nym ). The simulation engine can be used to play out different scenarios and better understand the relationship between the system's input (e.g. parameters of the reward scheme or initial stake distribution) and its convergence properties (does it converge to an equilibrium and if yes how quickly, how decentralized is the final allocation of stake to the different stakeholders, and so on). For details on how to install the engine and run simulations, see the Setup page; for a complete guide on how to customize the simulation, see the Configuration page; for a description of the different output files that a simulation produces, see the Output page, and for examples to get started with and draw inspiration from, see the Examples page. If you have questions about the project that are not covered in the documentation or any other remark you would like to share with us and the wider community, please visit our dedicated Discussions section on Github and start a new thread or participate in an existing discussion if it is relevant to your concern. Contributing This is an open source project licensed under the terms and conditions of the Apache 2.0 license . Everyone is welcome to contribute to it by proposing or implementing their ideas. Example contributions include, but are not limited to, adding a new feature to the simulation engine (e.g. integration of exchange rates), improving the performance of the simulations, or creating a user-friendly interface for configuring and running simulations. Note that all contributions to the project will be covered by the above-mentioned license. When making changes in the code, contributors are required to fork the project's repository first and then issue a pull request with their changes, which will be reviewed before being integrated to the main branch. Bugs can be reported in the Issues page, and all sorts of comments and ideas can be addressed in the project's Disccussions .","title":"Home"},{"location":"#rewards-sharing-simulation-engine-documentation","text":"This is the documentation for the Rewards Sharing Simulation Engine built by the University of Edinburgh's Blockchain Technology Lab. The source code is available on Github .","title":"Rewards Sharing Simulation Engine - Documentation"},{"location":"#overview","text":"The simulation models the behaviour of stakeholders in a Proof-of-Stake system, i.e. the way they use their stake to engage with the protocol depending on the rewards they expect to receive. It focuses particularly on the way different stakeholders combine their resources and create stake pools (it assumes an on-chain pooling mechanism like the one in Cardano) and follows the dynamics of the system until it (potentially) reaches an equilibrium. The implementation is based on the Cardano blockchain, but can be generalized to systems that use similar reward sharing schemes (e.g. Nym ). The simulation engine can be used to play out different scenarios and better understand the relationship between the system's input (e.g. parameters of the reward scheme or initial stake distribution) and its convergence properties (does it converge to an equilibrium and if yes how quickly, how decentralized is the final allocation of stake to the different stakeholders, and so on). For details on how to install the engine and run simulations, see the Setup page; for a complete guide on how to customize the simulation, see the Configuration page; for a description of the different output files that a simulation produces, see the Output page, and for examples to get started with and draw inspiration from, see the Examples page. If you have questions about the project that are not covered in the documentation or any other remark you would like to share with us and the wider community, please visit our dedicated Discussions section on Github and start a new thread or participate in an existing discussion if it is relevant to your concern.","title":"Overview"},{"location":"#contributing","text":"This is an open source project licensed under the terms and conditions of the Apache 2.0 license . Everyone is welcome to contribute to it by proposing or implementing their ideas. Example contributions include, but are not limited to, adding a new feature to the simulation engine (e.g. integration of exchange rates), improving the performance of the simulations, or creating a user-friendly interface for configuring and running simulations. Note that all contributions to the project will be covered by the above-mentioned license. When making changes in the code, contributors are required to fork the project's repository first and then issue a pull request with their changes, which will be reviewed before being integrated to the main branch. Bugs can be reported in the Issues page, and all sorts of comments and ideas can be addressed in the project's Disccussions .","title":"Contributing"},{"location":"configuration/","text":"Configuration The simulation engine is highly configurable. From the reward scheme parameters to be used to the output files to be generated, there are numerous variables that can vary from execution to execution. This customization is performed using command-line arguments when running the main.py or batch-run.py scripts. We will go through all the available options here, but it's also possible to get an overview of the arguments and their default values by running the corresponding help commands: python main.py --help python batch-run.py --help Remember though that all arguments are optional, so it is not mandatory to manually set values for any of them. If not value is explicitly provided, then the corresponding default value is used. Command-line options These are all the arguments that can be configured during execution from the command line: --n : The number of stakeholders / agents in the simulation. The default value is 1000, but any natural number is accepted. Note that the higher the value of n the slower the simulation becomes. --k : The target number of pools of the system (reward sharing scheme parameter). The default value is 100, but any natural number is accepted. Note that the higher the value of k the slower the simulation becomes. --a0 : Stake influence factor (reward sharing scheme parameter). The default value is 0.3, but any non-negative real number is accepted. --reward_scheme : The function that is used to calculate the rewards of a pool. There are currently five options, which correspond to the original reward function of Cardano (0), a simplified version of the original function (1), a version that uses flat pledge benefit (2), one that uses curve pledge benefit (3) which corresponds to the one proposed in CIP-7 and one that corresponds to CIP-50 (4). More reward schemes can be easily added by extending the relevant class. Please note, however, that our methodology includes heuristics that were designed based on the current reward scheme of Cardano, so it might need some adjustments to yield meaningful results when used with different reward schemes. --agent_profile_distr : List of weights that determine how agents are distributed across the different behavioral profiles. Currently, there are three different profiles: non-myopic stakeholder, myopic stakeholder and abstainer. When using this argument, one must provide a number of values equal to the number of profiles. The default is [1, 0, 0], i.e. there are only non-myopic agents. Any non-negative real numbers can be used for the weights (they don't have to explicitly sum to 1), e.g. [4, 2, 1] dictates that there will be (roughly) twice as many non-myopic agents compared to myopic ones and that the myopic ones will be (roughly) twice as many as the abstainers. --cost_min : The lowest initial cost that a stakeholder can have (acts as the lower bound of the Uniform distribution that cost values are drawn from). The default value is 10 -5 , but any non-negative real number is accepted. --cost_max : The highest initial cost that a stakeholder can have (acts as the upper bound of the Uniform distribution that cost values are drawn from). The default value is 10 -4 , but any non-negative real number > cost_min is accepted. extra_pool_cost_fraction : When an agent operates one pool, then the cost of the pool is equal to the cost of the agent. However, in our simulation it's possible for agents to operate multiple pools, so we assume that each additional pool an agent operates costs a fraction of their initial cost, and that fraction is the same for all agents and dictated by this argument. The default value is 0.4 (i.e. that a second pool costs 0.4 times as much as the first), but any non-negative real number is accepted (if we assume economies of scale then this value must be < 1, but if we assume some sort of Sybil cost then it can also be >= 1). --agent_activation_order : The order in which agents get activated. The default option is \"Random\", meaning that the order changes for each round, while the other options are \"Sequential\" for activating agents in the same order every time (based on their ids) and \"Semisimultaneous\" for activating a number of them simultaneously before moving on. --absolute_utility_threshold : The absolute utility threshold for accepting new moves (relates to inertia). If an agent develops a new strategy whose utility does not exceed that of its current one by at least this threshold, then the new strategy is rejected. The default value is 10 -9 , but any non-negative real number is accepted. --relative_utility_threshold : The relative utility threshold for accepting new moves (relates to inertia). If an agent develops a new strategy whose utility does not exceed that of its current one by at least this fraction, then the new strategy is rejected. The default value is 0, i.e. no relative utility threshold exists, but any non-negative real number is accepted. For example, if this threshold is 0.1 then it means that a new move has to yield utility at least 10% higher than that of the current move in order to be selected. --stake_distr_source : The distribution to use for the initial allocation of stake to the agents. The default choice is \"Pareto\", but other options include \"Flat\" for a distribution where all agents start with equal stake and \"File\" where a custom distribution is read from a csv file. In the latter case, the relevant file is expected to be at the root directory of the project, contain only stake values separated by commas and be named synthetic-stake-distribution-X-agents.csv where X is the number of agents used. --pareto_param : The parameter that determines the shape of the Pareto distribution that the stake is sampled from (only relevant if stake_distr_source is set to \"pareto\"). The default value is 2 but any positive real number is accepted. --inactive_stake_fraction : The fraction of the total stake of the system that remains inactive (is not allocated to any of the agents). The default value is 0, meaning that the active stake of the system is equal to the total stake, but any value between 0 and 1 is accepted. --inactive_stake_fraction_known : Flag that determines whether the fraction of the system's stake that is inactive is known upon the launch of the simulation (only relevant when there is inactive stake). If this fraction is known, then the simulation automatically adjusts the target number of pools k. The default setting is for it to remain unknown. --iterations_after_convergence : The minimum consecutive idle iterations that are required before the simulation declares convergence to an equilibrium and terminates. The default value is 10, but any natural number is accepted. --max_iterations : The maximum number of iterations that the simulation will perform before terminating. The default is 2000, but any natural number is accepted (it is recommended to keep this number high, in order to give the opportunity for simulations to converge to equilibria). --metrics : A list of ids that correspond to metrics that are tracked during the simulation. Default is [1, 2, 3, 4, 6, 17, 18, 24, 25]. For the full list of metrics and their corresponding identifiers, see the Metrics page. --generate_graphs : A flag that determines whether graphs relating to the tracked metrics are generated upon termination of the simulation. By default, this is activated. --seed : The seed to be used by the pseudorandom generator - can be specified to allow for reproducibility of the results. The default value is 'None', which means that a seed is chosen at random (can be accessed through the output of the simulation). Any non-negative integer can be accepted as the seed. --execution_id : An optional identifier for the specific execution of the simulation run, which is used for naming the output folder / files. If no identifier is provided, then one is generated automatically. --input_from_file : A flag that determines whether the input is read from a file (must be named \"args.json\" and be placed in the root directory of the project). If this is activated, then any other command line arguments are discarded. By default, this flag is not activated.","title":"Configuration"},{"location":"configuration/#configuration","text":"The simulation engine is highly configurable. From the reward scheme parameters to be used to the output files to be generated, there are numerous variables that can vary from execution to execution. This customization is performed using command-line arguments when running the main.py or batch-run.py scripts. We will go through all the available options here, but it's also possible to get an overview of the arguments and their default values by running the corresponding help commands: python main.py --help python batch-run.py --help Remember though that all arguments are optional, so it is not mandatory to manually set values for any of them. If not value is explicitly provided, then the corresponding default value is used.","title":"Configuration"},{"location":"configuration/#command-line-options","text":"These are all the arguments that can be configured during execution from the command line: --n : The number of stakeholders / agents in the simulation. The default value is 1000, but any natural number is accepted. Note that the higher the value of n the slower the simulation becomes. --k : The target number of pools of the system (reward sharing scheme parameter). The default value is 100, but any natural number is accepted. Note that the higher the value of k the slower the simulation becomes. --a0 : Stake influence factor (reward sharing scheme parameter). The default value is 0.3, but any non-negative real number is accepted. --reward_scheme : The function that is used to calculate the rewards of a pool. There are currently five options, which correspond to the original reward function of Cardano (0), a simplified version of the original function (1), a version that uses flat pledge benefit (2), one that uses curve pledge benefit (3) which corresponds to the one proposed in CIP-7 and one that corresponds to CIP-50 (4). More reward schemes can be easily added by extending the relevant class. Please note, however, that our methodology includes heuristics that were designed based on the current reward scheme of Cardano, so it might need some adjustments to yield meaningful results when used with different reward schemes. --agent_profile_distr : List of weights that determine how agents are distributed across the different behavioral profiles. Currently, there are three different profiles: non-myopic stakeholder, myopic stakeholder and abstainer. When using this argument, one must provide a number of values equal to the number of profiles. The default is [1, 0, 0], i.e. there are only non-myopic agents. Any non-negative real numbers can be used for the weights (they don't have to explicitly sum to 1), e.g. [4, 2, 1] dictates that there will be (roughly) twice as many non-myopic agents compared to myopic ones and that the myopic ones will be (roughly) twice as many as the abstainers. --cost_min : The lowest initial cost that a stakeholder can have (acts as the lower bound of the Uniform distribution that cost values are drawn from). The default value is 10 -5 , but any non-negative real number is accepted. --cost_max : The highest initial cost that a stakeholder can have (acts as the upper bound of the Uniform distribution that cost values are drawn from). The default value is 10 -4 , but any non-negative real number > cost_min is accepted. extra_pool_cost_fraction : When an agent operates one pool, then the cost of the pool is equal to the cost of the agent. However, in our simulation it's possible for agents to operate multiple pools, so we assume that each additional pool an agent operates costs a fraction of their initial cost, and that fraction is the same for all agents and dictated by this argument. The default value is 0.4 (i.e. that a second pool costs 0.4 times as much as the first), but any non-negative real number is accepted (if we assume economies of scale then this value must be < 1, but if we assume some sort of Sybil cost then it can also be >= 1). --agent_activation_order : The order in which agents get activated. The default option is \"Random\", meaning that the order changes for each round, while the other options are \"Sequential\" for activating agents in the same order every time (based on their ids) and \"Semisimultaneous\" for activating a number of them simultaneously before moving on. --absolute_utility_threshold : The absolute utility threshold for accepting new moves (relates to inertia). If an agent develops a new strategy whose utility does not exceed that of its current one by at least this threshold, then the new strategy is rejected. The default value is 10 -9 , but any non-negative real number is accepted. --relative_utility_threshold : The relative utility threshold for accepting new moves (relates to inertia). If an agent develops a new strategy whose utility does not exceed that of its current one by at least this fraction, then the new strategy is rejected. The default value is 0, i.e. no relative utility threshold exists, but any non-negative real number is accepted. For example, if this threshold is 0.1 then it means that a new move has to yield utility at least 10% higher than that of the current move in order to be selected. --stake_distr_source : The distribution to use for the initial allocation of stake to the agents. The default choice is \"Pareto\", but other options include \"Flat\" for a distribution where all agents start with equal stake and \"File\" where a custom distribution is read from a csv file. In the latter case, the relevant file is expected to be at the root directory of the project, contain only stake values separated by commas and be named synthetic-stake-distribution-X-agents.csv where X is the number of agents used. --pareto_param : The parameter that determines the shape of the Pareto distribution that the stake is sampled from (only relevant if stake_distr_source is set to \"pareto\"). The default value is 2 but any positive real number is accepted. --inactive_stake_fraction : The fraction of the total stake of the system that remains inactive (is not allocated to any of the agents). The default value is 0, meaning that the active stake of the system is equal to the total stake, but any value between 0 and 1 is accepted. --inactive_stake_fraction_known : Flag that determines whether the fraction of the system's stake that is inactive is known upon the launch of the simulation (only relevant when there is inactive stake). If this fraction is known, then the simulation automatically adjusts the target number of pools k. The default setting is for it to remain unknown. --iterations_after_convergence : The minimum consecutive idle iterations that are required before the simulation declares convergence to an equilibrium and terminates. The default value is 10, but any natural number is accepted. --max_iterations : The maximum number of iterations that the simulation will perform before terminating. The default is 2000, but any natural number is accepted (it is recommended to keep this number high, in order to give the opportunity for simulations to converge to equilibria). --metrics : A list of ids that correspond to metrics that are tracked during the simulation. Default is [1, 2, 3, 4, 6, 17, 18, 24, 25]. For the full list of metrics and their corresponding identifiers, see the Metrics page. --generate_graphs : A flag that determines whether graphs relating to the tracked metrics are generated upon termination of the simulation. By default, this is activated. --seed : The seed to be used by the pseudorandom generator - can be specified to allow for reproducibility of the results. The default value is 'None', which means that a seed is chosen at random (can be accessed through the output of the simulation). Any non-negative integer can be accepted as the seed. --execution_id : An optional identifier for the specific execution of the simulation run, which is used for naming the output folder / files. If no identifier is provided, then one is generated automatically. --input_from_file : A flag that determines whether the input is read from a file (must be named \"args.json\" and be placed in the root directory of the project). If this is activated, then any other command line arguments are discarded. By default, this flag is not activated.","title":"Command-line options"},{"location":"examples/","text":"Examples Here, we provide some examples that can help better understand the capacities of the simulation engine. We divide the examples in sections, depending on the type of execution (single run or batch run). Note that in all examples below, we assume that the python command corresponds to a Python 3.9 installation and that the commands are executed from the root directory of the project. Recall that when an argument is not set explicitly then its default value is used (for all arguments and their default values see the Configuration ) page). Single runs Run with 1000 agents, k = 100 and a0 = 0.3: python main.py --n=1000 --k=100 --a0=0.3 --execution_id=baseline Run with two phases, first with k = 100 and then k = 200: python main.py --k 100 200 --execution_id=increasing-k Run with 3,000 agents, k = 500 and a specified seed (42): python main.py --n=3000 --k=500 --seed=42 --execution_id=n-3K-k-500-seed-42 Run with 50% of the agents being myopic: python main.py --agent_profile_distr 1 1 0 Batch runs Batch run with 1000 agents and 5 different values for k (100, 200, 300, 400, 500): python batch-run.py --n=1000 --k 100 200 300 400 500 --execution_id=batch-run-varying-k Batch run with 1000 agents, k = 100 and 3 different values for a0 (0.01, 0.1, 1): python batch-run.py --n=1000 --k=100 --a0 0.01 0.1 1 --execution_id=batch-run-varying-a0 Batch run with two variables, using 3 values for k and 3 values for a0 (total of 9 combinations): python batch-run.py --n=500 --k 50 100 150 --a0 0.05 0.1 0.3 --execution_id=batch-run-varying-k-a0-3x3","title":"Examples"},{"location":"examples/#examples","text":"Here, we provide some examples that can help better understand the capacities of the simulation engine. We divide the examples in sections, depending on the type of execution (single run or batch run). Note that in all examples below, we assume that the python command corresponds to a Python 3.9 installation and that the commands are executed from the root directory of the project. Recall that when an argument is not set explicitly then its default value is used (for all arguments and their default values see the Configuration ) page).","title":"Examples"},{"location":"examples/#single-runs","text":"Run with 1000 agents, k = 100 and a0 = 0.3: python main.py --n=1000 --k=100 --a0=0.3 --execution_id=baseline Run with two phases, first with k = 100 and then k = 200: python main.py --k 100 200 --execution_id=increasing-k Run with 3,000 agents, k = 500 and a specified seed (42): python main.py --n=3000 --k=500 --seed=42 --execution_id=n-3K-k-500-seed-42 Run with 50% of the agents being myopic: python main.py --agent_profile_distr 1 1 0","title":"Single runs"},{"location":"examples/#batch-runs","text":"Batch run with 1000 agents and 5 different values for k (100, 200, 300, 400, 500): python batch-run.py --n=1000 --k 100 200 300 400 500 --execution_id=batch-run-varying-k Batch run with 1000 agents, k = 100 and 3 different values for a0 (0.01, 0.1, 1): python batch-run.py --n=1000 --k=100 --a0 0.01 0.1 1 --execution_id=batch-run-varying-a0 Batch run with two variables, using 3 values for k and 3 values for a0 (total of 9 combinations): python batch-run.py --n=500 --k 50 100 150 --a0 0.05 0.1 0.3 --execution_id=batch-run-varying-k-a0-3x3","title":"Batch runs"},{"location":"metrics/","text":"Metrics There are several metrics, or model reporters, that can be tracked during a simulation. Each of them is associated with an id for convenience. We provide details for all of them below: Pool count : the number of active pools in the system. Total pledge : the total pledged stake of the system (sum of all pools' pledges). Mean pledge : the average value of stake that is pledged in pools. Median pledge : the median value of stake that is pledged in pools. Average pools per operator : the average number of pools that an operator controls. Max pools per operator : the maximum number of pools that an operator controls. Median pools per operator : the median number of pools that an operator controls. Average saturation rate : the average saturation rate (stake / saturation threshold) across all active pools. Nakamoto coefficient : the minimum number of entities that collectively control more than 50% of the system's active stake through their pools. Statistical distance : the statistical distance of the distributions of the stake that agents controlled at the beginning of the simulation vs on this round. Min-aggregate pledge : the minimum aggregate pledge of pools that collectively control more than 50% of the system's active stake. Note that the calculation of this metric is slow because of the complexity of the problem. Pledge rate : the fraction of active stake that is used as pledge (total pledge / total active stake). Pool homogeneity factor : a metric that describes how homogeneous the pools of the system are (the highest possible value is 1, which is given when all pools have the same size). Iterations : the number of iterations that the simulation has gone through. Mean stake rank : the average rank of pool operators regarding their initial stake. Mean cost rank : the average rank of pool operators regarding their initial cost. Median stake rank : the median rank of pool operators regarding their initial stake. Median cost rank : the median rank of pool operators regarding their initial cost. Number of pool splitters : the number of stakeholders that operate two or more pools. Cost efficient stakeholders : the number of agents for whom it is possible to make profit by operating a pool. StakePairs : a mapping of each pool id to its stake and profit margin. Gini-id : a variation of the gini coefficient, where we consider each agent as an \u201cid\u201d and each pool as a \u201ccoin\u201d. Then the gini-id is the gini coefficient considering each party with the coins they have. In case of each agent operating one pool this coefficient is 0. Gini-id stake : like the gini-id above, but considering the total stake each agent controls through their pools instead of the number of pools they operate. Mean margin : the average profit margin across all active pools. Median margin : the median profit margin across all active pools. Stake per agent : a list where each element corresponds to the total stake controlled through an agent's pool for some agent Stake per agent id : a mapping of each agent id to the total stake that said agent controls through their pools. Total delegated stake : the total stake delegated to active pools (including pledged stake). Total agent stake : the total stake held by agents. Operator count : the number of stakeholders that operate pools. Refer to the Configuration page for details on specifying which metrics will be used during a simulation.","title":"Metrics"},{"location":"metrics/#metrics","text":"There are several metrics, or model reporters, that can be tracked during a simulation. Each of them is associated with an id for convenience. We provide details for all of them below: Pool count : the number of active pools in the system. Total pledge : the total pledged stake of the system (sum of all pools' pledges). Mean pledge : the average value of stake that is pledged in pools. Median pledge : the median value of stake that is pledged in pools. Average pools per operator : the average number of pools that an operator controls. Max pools per operator : the maximum number of pools that an operator controls. Median pools per operator : the median number of pools that an operator controls. Average saturation rate : the average saturation rate (stake / saturation threshold) across all active pools. Nakamoto coefficient : the minimum number of entities that collectively control more than 50% of the system's active stake through their pools. Statistical distance : the statistical distance of the distributions of the stake that agents controlled at the beginning of the simulation vs on this round. Min-aggregate pledge : the minimum aggregate pledge of pools that collectively control more than 50% of the system's active stake. Note that the calculation of this metric is slow because of the complexity of the problem. Pledge rate : the fraction of active stake that is used as pledge (total pledge / total active stake). Pool homogeneity factor : a metric that describes how homogeneous the pools of the system are (the highest possible value is 1, which is given when all pools have the same size). Iterations : the number of iterations that the simulation has gone through. Mean stake rank : the average rank of pool operators regarding their initial stake. Mean cost rank : the average rank of pool operators regarding their initial cost. Median stake rank : the median rank of pool operators regarding their initial stake. Median cost rank : the median rank of pool operators regarding their initial cost. Number of pool splitters : the number of stakeholders that operate two or more pools. Cost efficient stakeholders : the number of agents for whom it is possible to make profit by operating a pool. StakePairs : a mapping of each pool id to its stake and profit margin. Gini-id : a variation of the gini coefficient, where we consider each agent as an \u201cid\u201d and each pool as a \u201ccoin\u201d. Then the gini-id is the gini coefficient considering each party with the coins they have. In case of each agent operating one pool this coefficient is 0. Gini-id stake : like the gini-id above, but considering the total stake each agent controls through their pools instead of the number of pools they operate. Mean margin : the average profit margin across all active pools. Median margin : the median profit margin across all active pools. Stake per agent : a list where each element corresponds to the total stake controlled through an agent's pool for some agent Stake per agent id : a mapping of each agent id to the total stake that said agent controls through their pools. Total delegated stake : the total stake delegated to active pools (including pledged stake). Total agent stake : the total stake held by agents. Operator count : the number of stakeholders that operate pools. Refer to the Configuration page for details on specifying which metrics will be used during a simulation.","title":"Metrics"},{"location":"output/","text":"Output Every time the simulation engine is used, it produces some output files to describe the simulations that were executed. All these files are saved within a folder named \u201coutput\u201d, which is created automatically if it doesn't already exist. Output from single run Each execution of the simulation generates a new folder for the output of that specific execution. The folder is named based on the local serial number 1 of the execution and a user-provided identifier (or an automatically generated one if the user does not define one for that instance). Specifically, the folder is populated with the following: Files that characterize the input of the execution args.json : A json file that lists all the parameters of the simulation and the values they take during this execution. initial-state-descriptors.json : A json file that describes the initial state of the system for this execution, including the highest and lowest stake values owned by the stakeholders, the Nakamoto coefficient prior (how many stakeholders collectively control the majority of the stake before any pooling takes place), and more. The number that was used as the seed for pseudo-randomness is also listed there, to allow for reproducibility of the results. Files that track the evolution of the execution metrics.csv : A csv file that reports various metrics for each round of the simulation (e.g. pool count or total pledge). The specific metrics that are tracked depend on the input of the simulation (see the relevant part of the Configuration page for all options). Figures : If the relevant option is activated (see Configuration ), a graph is produced for each tracked metric, illustrating its evolution throughout the course of the simulation. Files that characterize the outcome of the execution final-state-descriptors.json : A json file that describes the final state of the system for this execution, including the number of pools, the number of distinct operators, and more. It is also stated in this file whether the simulation reached an equilibrium or not. final-state-pools.csv : A csv file that lists information about the pools that are active in the system upon termination of the simulation. This includes for each pool its owner's id, its pledge, total stake, profit margin, and more. final-state-stakeholders.csv : A csv file that lists information about the stakeholders upon termination of the simulation. This includes predetermined attributes, like the initial stake or cost value of a stakeholder, as well as characteristics relating to the final state of the simulation, such as the number of pools they end up operating or the total stake they control through their pools. simulation-object.pkl : A pickled file containing the instance of the simulation as a Python object (only useful for developers that may want to use it to extract more data). For example, running the simulation for the first time with \"simulation-test\" as the execution id produces a folder that looks like this: Output from batch run Similarly with the single run, each batch run execution generates a new folder, which is named based on the local serial number and a user-provided identifier (or the generic \"batch-run\" if the user does not define an id for that instance). Within this folder, more folders are created, each corresponding to an instance of the simulation and having the format described above. In the case of batch runs, one more file is created, which contains aggregate results (some metrics for each simulation instance) and is used to create graphs (saved under \"Figures\") and compare the different executions and the impact of the changing input. For example, executing a batch run the second time the simulation engine is used, with \"batch-run-varying-k\" as the execution id produces a folder that looks like this: 1 : Keeping track of the serial number is done using a local file named \"sequence.dat\".","title":"Output"},{"location":"output/#output","text":"Every time the simulation engine is used, it produces some output files to describe the simulations that were executed. All these files are saved within a folder named \u201coutput\u201d, which is created automatically if it doesn't already exist.","title":"Output"},{"location":"output/#output-from-single-run","text":"Each execution of the simulation generates a new folder for the output of that specific execution. The folder is named based on the local serial number 1 of the execution and a user-provided identifier (or an automatically generated one if the user does not define one for that instance). Specifically, the folder is populated with the following:","title":"Output from single run"},{"location":"output/#files-that-characterize-the-input-of-the-execution","text":"args.json : A json file that lists all the parameters of the simulation and the values they take during this execution. initial-state-descriptors.json : A json file that describes the initial state of the system for this execution, including the highest and lowest stake values owned by the stakeholders, the Nakamoto coefficient prior (how many stakeholders collectively control the majority of the stake before any pooling takes place), and more. The number that was used as the seed for pseudo-randomness is also listed there, to allow for reproducibility of the results.","title":"Files that characterize the input of the execution"},{"location":"output/#files-that-track-the-evolution-of-the-execution","text":"metrics.csv : A csv file that reports various metrics for each round of the simulation (e.g. pool count or total pledge). The specific metrics that are tracked depend on the input of the simulation (see the relevant part of the Configuration page for all options). Figures : If the relevant option is activated (see Configuration ), a graph is produced for each tracked metric, illustrating its evolution throughout the course of the simulation.","title":"Files that track the evolution of the execution"},{"location":"output/#files-that-characterize-the-outcome-of-the-execution","text":"final-state-descriptors.json : A json file that describes the final state of the system for this execution, including the number of pools, the number of distinct operators, and more. It is also stated in this file whether the simulation reached an equilibrium or not. final-state-pools.csv : A csv file that lists information about the pools that are active in the system upon termination of the simulation. This includes for each pool its owner's id, its pledge, total stake, profit margin, and more. final-state-stakeholders.csv : A csv file that lists information about the stakeholders upon termination of the simulation. This includes predetermined attributes, like the initial stake or cost value of a stakeholder, as well as characteristics relating to the final state of the simulation, such as the number of pools they end up operating or the total stake they control through their pools. simulation-object.pkl : A pickled file containing the instance of the simulation as a Python object (only useful for developers that may want to use it to extract more data). For example, running the simulation for the first time with \"simulation-test\" as the execution id produces a folder that looks like this:","title":"Files that characterize the outcome of the execution"},{"location":"output/#output-from-batch-run","text":"Similarly with the single run, each batch run execution generates a new folder, which is named based on the local serial number and a user-provided identifier (or the generic \"batch-run\" if the user does not define an id for that instance). Within this folder, more folders are created, each corresponding to an instance of the simulation and having the format described above. In the case of batch runs, one more file is created, which contains aggregate results (some metrics for each simulation instance) and is used to create graphs (saved under \"Figures\") and compare the different executions and the impact of the changing input. For example, executing a batch run the second time the simulation engine is used, with \"batch-run-varying-k\" as the execution id produces a folder that looks like this: 1 : Keeping track of the serial number is done using a local file named \"sequence.dat\".","title":"Output from batch run"},{"location":"setup/","text":"Setup Dependencies The simulation engine is written in Python 3.9, so the first thing to ensure when running it on some machine is that Python 3.9 is installed there. The remaining dependencies of the project can be found in the requirements file . Running the following from the root directory of the project installs all required packages in one go (assuming that the python command corresponds to a Python 3.9 installation): python -m pip install -r requirements.txt Installation Installing the simulation engine is very simple, as it only involves cloning the relevant Github project : git clone https://github.com/Blockchain-Technology-Lab/Rewards-Sharing-Simulation-Engine.git Execution To run the simulation, navigate to the directory of the project and run the main.py script from a terminal: python main.py This executes the simulation with the default options (1000 agents, k = 100, a0 = 0.3, and so on). It is also possible to run the simulation with different parameters. For example, to if we want a simulation with 10,000 agents and target number of pools k = 500, we can run the following: python main.py --n=10000 --k=500 For the full list of options that the simulation accepts, refer to the Configuration page, and for examples of using the simulation engine in different ways see the Examples page.","title":"Setup"},{"location":"setup/#setup","text":"","title":"Setup"},{"location":"setup/#dependencies","text":"The simulation engine is written in Python 3.9, so the first thing to ensure when running it on some machine is that Python 3.9 is installed there. The remaining dependencies of the project can be found in the requirements file . Running the following from the root directory of the project installs all required packages in one go (assuming that the python command corresponds to a Python 3.9 installation): python -m pip install -r requirements.txt","title":"Dependencies"},{"location":"setup/#installation","text":"Installing the simulation engine is very simple, as it only involves cloning the relevant Github project : git clone https://github.com/Blockchain-Technology-Lab/Rewards-Sharing-Simulation-Engine.git","title":"Installation"},{"location":"setup/#execution","text":"To run the simulation, navigate to the directory of the project and run the main.py script from a terminal: python main.py This executes the simulation with the default options (1000 agents, k = 100, a0 = 0.3, and so on). It is also possible to run the simulation with different parameters. For example, to if we want a simulation with 10,000 agents and target number of pools k = 500, we can run the following: python main.py --n=10000 --k=500 For the full list of options that the simulation accepts, refer to the Configuration page, and for examples of using the simulation engine in different ways see the Examples page.","title":"Execution"}]}